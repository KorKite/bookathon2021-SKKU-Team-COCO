# 성균관대학교 2021 AI x Bookathon 인공지능 글쓰기
    ✅ 성균관대학교 학술정보관과 인공지능대학원이 주관한 인공지능으로 글쓰기 대회입니.
    ✅ 저희 팀은 3등을 수상했습니다!!
    
## 출전 신청
    저희 팀은 오래 준비하 수 있는 시간이 부족했습니다. 
    대회의 출전 가능기간 바로 직전에 출전을 하겠다고 제출을 했고, 1달동안 준비했던 다른 팀들에 비해 시간적으로 부족했습니다.
    
## 1차 예선 -> 인공지능 관련 시험
    작년과 달리, 대회에 출전한 팀이 많아 transfer learning, gpt와 관련한 문제를 풀어서 1차 예선을 통과했습니다.
    문제 자체는 매우 쉬웠으나, 다른 팀보다 나은 답변을 제출하려고 하다보니 쓸 내용이 많았습니다.
    구글에 찾아보면 정답을 찾을 수 있으나, 저희는 저희 팀의 생각을 최대한 풀어내고자 노력했습니다.
    3시간동안 답안을 작성하였는데, 마지막엔 검토할 시간이 부족했습니다.
    
## 합격자 gift
    삼성학술정보관에서 과자와 기념품을 보내주셨습니다. 또한 위생에 필요한 마스크와 손 소독제 역시 수령했습니다.
    
## 2차 본선
    2차 본선은 오후 3시부터 시작하여 다음날 5시까지 총 26시간동안 진행했습니다.
    코로나로 인하여, 원래는 삼성학술정보관(자과캠)에서 모여서 진행했으나, 올해는 각자 팀별로 모였습니다.
    저희는 제 자취방에 모여 26시간의 여정을 시작했습니다. 
    웹액스를 통해 서로 소통하도록 했는데, 마스크를 계속 쓰도록 해서 굉장히 힘들었습니다.

## 인공지능 모델
    마인즈랩에서 서버와 사전학습된 모델을 제공해주셨습니다.
    뉴스로 사전학습된 gpt2모델을 훈련하여 수필을 쓰도록 fine-tuning하는 것이 목표입니다.
    다른 팀은 미리 수필을 크롤링한 팀도 있었는데, 저희는 사전학습기간에 크롤링을 시작했습니다.
    
## 크롤링한 데이터 & 전처리
    저희팀은 브런치에서 5000개의 여행관련한 수필을 크롤링했습니다.
    여행관련한 수필을 크롤링한 이유는 어떤 주제가 제시되어도 여행과 관련하여 풀어낸다면 쉬울 것이라는 판단에서였습니다.
    또한 저희는 특별한 전처리 방법을 사용하였는데, 바로 '인간 전처리기'입니다.
    우리 팀에서 직접 내용을 하나하나 열어서 스팸이나 이상한 내용은 거르고, 맞춤법을 직접 검사하여 인풋으로 사용했습니다.
    이것이 모델의 품질을 높인 하나의 전략이었습니다.
    
## 모델 훈련 전략
    저희는 2번 데이터르 넣어주었는데, 
    처음은 조금 약하게 전처리한 4mb의 데이터, 그리고 강하게 전처리한 1mb의 데이터르 활용했습니다.
    첫번째는 많은 양의 데이터로 수필의 문체를 학습했고, 두번째는 퀄리티 있는 글을 생산하도록 훈련을 했습니다.
    이를 통해 조금 더 로버스트한 모델을 생산할 수 있었습니다.
    
    또한, Learning Rate Decay를 활용해주었습니다. 
    로컬 미니멈에 빠지지 않도록 초반에는 높은 learning rate를 유지하다가,
    글로벌 미니멈에 근접할 수록 learning rate를 낮춰가는 학습법입니다.
    이를 통해 엄청나게 loss를 감소하는 동시에 global minimun으로 모델을 이끌 수 있었습니다.
